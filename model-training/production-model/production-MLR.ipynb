{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![Alt text](../images/logistic-regression-tokenizer.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Multinomial Logistic Regression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this notebook, the MLR is trained and tested. Afterwards, [unseen unlabeled reddit messages](unseen-data.csv) is passed through the recently trained model obtaining a [labeled dataset](predictions-unseen.csv) which predicts so good so far. This is the model that will be used in production, running in a EC2 instance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import libraries\n",
    "\n",
    "# sparkML\n",
    "from pyspark.ml.feature import Tokenizer, StopWordsRemover, CountVectorizer, IDF, StringIndexer\n",
    "from pyspark.ml.evaluation import MulticlassClassificationEvaluator\n",
    "from pyspark.ml.tuning import ParamGridBuilder, CrossValidator\n",
    "from pyspark.ml.classification import LogisticRegression\n",
    "from pyspark.ml import Pipeline\n",
    "\n",
    "# sparkSQL\n",
    "from pyspark.sql.functions import udf, col, when\n",
    "from pyspark.sql.types import StringType, DoubleType\n",
    "from pyspark.sql import SparkSession\n",
    "\n",
    "# other\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "import nltk\n",
    "import csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\HP\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\HP\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     C:\\Users\\HP\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Download nltk functions --> Necessary to remove stopwords and more to get better accuracy in our NLP ML model\n",
    "nltk.download(\"punkt\")\n",
    "nltk.download(\"stopwords\")\n",
    "nltk.download(\"wordnet\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize SparkSession\n",
    "spark = SparkSession.builder.appName(\"TextClassification\").getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "# UDF for preprocessing\n",
    "def preprocess_text(text):\n",
    "    '''Remove stop words, tokenize and clean the data from the title column. Original: |Cis Men of Reddit, if you were a woman, what would you like about Men?  --> PROCESSED: men reddit woman would like men''' \n",
    "    tokens = nltk.word_tokenize(text.lower(), language=\"english\")\n",
    "    tokens = [word for word in tokens if word.isalnum() and len(word) > 1]\n",
    "    tokens = [lemmatizer.lemmatize(word, pos=\"v\") for word in tokens if word not in stop_words]\n",
    "    return ' '.join(tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Load the labeled dataset into spark\n",
    "df = spark.read.csv(\"../labeled-dataset/labeled-training-dataset.csv\", header=True, inferSchema=True)\n",
    "\n",
    "# We need a copy of the column, as we are going to tokenize and vektorize the title to better classification\n",
    "df = df.withColumn(\"original_title\", df[\"title\"])\n",
    "\n",
    "# Data Preprocessing\n",
    "lemmatizer = WordNetLemmatizer()\n",
    "stop_words = set(nltk.corpus.stopwords.words(\"english\"))\n",
    "\n",
    "# Create a list of unique values of the topic_name column in the csv file. Eventually, you will find some rows that contain a really rare character combination, so you avoid it creating specific previous topics.\n",
    "TARGET_CLASSES = [\"money\", \"food\", \"job\", \"life\", \"music\", \"media\", \"movie\", \"sexual\", \"health\", \"kid\", \"game\", \"book\", \"tech\", \"relationships\"]\n",
    "\n",
    "# Filter out the elements that are not falling in any of the classes due to a SyntaxError in the Reddit Sentence --> \"Is calling someone a \"\"plaything\"\" a porn term? If so, what type of porn/ kink content?\",sexual [Look at that combination of double \"\"]\n",
    "df = df.filter(df[\"topic_name\"].isin(TARGET_CLASSES))\n",
    "\n",
    "preprocess_udf = udf(preprocess_text, StringType())\n",
    "df = df.withColumn(\"title\", preprocess_udf(df[\"title\"]))\n",
    "\n",
    "# Convert the topic_name column to numeric\n",
    "indexer = StringIndexer(inputCol=\"topic_name\", outputCol=\"label\")\n",
    "indexed_df = indexer.fit(df).transform(df)\n",
    "indexed_df = indexed_df.withColumn(\"label\", col(\"label\").cast(\"integer\"))\n",
    "\n",
    "# Split the dataset\n",
    "(train_df, test_df) = indexed_df.randomSplit([0.8, 0.2], seed=42)\n",
    "\n",
    "# TF-IDF Vectorization --> Classic steps prior to train a Multiclassification model in NLP\n",
    "tokenizer = Tokenizer(inputCol=\"title\", outputCol=\"words\")\n",
    "remover = StopWordsRemover(inputCol=\"words\", outputCol=\"filtered_words\")\n",
    "cv = CountVectorizer(inputCol=\"filtered_words\", outputCol=\"raw_features\", vocabSize=1500)\n",
    "idf = IDF(inputCol=\"raw_features\", outputCol=\"features\")\n",
    "\n",
    "# Logistic Regression model\n",
    "lr = LogisticRegression(labelCol=\"label\", featuresCol=\"features\")\n",
    "\n",
    "# Modify the pipeline to use Logistic Regression\n",
    "pipeline = Pipeline(stages=[tokenizer, remover, cv, idf, lr])\n",
    "\n",
    "# Hyperparameter Tuning for Logistic Regression\n",
    "paramGrid = ParamGridBuilder() \\\n",
    "    .addGrid(lr.regParam, [0.01, 0.1, 0.5]).addGrid(lr.elasticNetParam, [0.0, 0.1, 0.5]).build()\n",
    "\n",
    "evaluator = MulticlassClassificationEvaluator(labelCol=\"label\", metricName=\"accuracy\")\n",
    "\n",
    "crossval = CrossValidator(estimator=pipeline, estimatorParamMaps=paramGrid, evaluator=evaluator, numFolds=5, seed=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fit the model\n",
    "cvModel = crossval.fit(train_df)\n",
    "\n",
    "# Make predictions\n",
    "predictions = cvModel.transform(test_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.6544\n",
      "Classification Report for Testing Data:\n",
      "Topic: money\n",
      "Precision: 0.4828\n",
      "Recall: 0.5185\n",
      "F1-Score: 0.5000\n",
      "Support: 27\n",
      "\n",
      "Topic: food\n",
      "Precision: 0.6774\n",
      "Recall: 0.7241\n",
      "F1-Score: 0.7000\n",
      "Support: 29\n",
      "\n",
      "Topic: job\n",
      "Precision: 0.3696\n",
      "Recall: 0.6538\n",
      "F1-Score: 0.4722\n",
      "Support: 26\n",
      "\n",
      "Topic: life\n",
      "Precision: 0.8571\n",
      "Recall: 0.7500\n",
      "F1-Score: 0.8000\n",
      "Support: 24\n",
      "\n",
      "Topic: music\n",
      "Precision: 0.7368\n",
      "Recall: 0.5385\n",
      "F1-Score: 0.6222\n",
      "Support: 26\n",
      "\n",
      "Topic: media\n",
      "Precision: 0.7619\n",
      "Recall: 0.6957\n",
      "F1-Score: 0.7273\n",
      "Support: 23\n",
      "\n",
      "Topic: movie\n",
      "Precision: 0.4000\n",
      "Recall: 0.4667\n",
      "F1-Score: 0.4308\n",
      "Support: 30\n",
      "\n",
      "Topic: sexual\n",
      "Precision: 0.7222\n",
      "Recall: 0.5909\n",
      "F1-Score: 0.6500\n",
      "Support: 22\n",
      "\n",
      "Topic: health\n",
      "Precision: 0.8750\n",
      "Recall: 0.8750\n",
      "F1-Score: 0.8750\n",
      "Support: 24\n",
      "\n",
      "Topic: kid\n",
      "Precision: 0.9500\n",
      "Recall: 0.7600\n",
      "F1-Score: 0.8444\n",
      "Support: 25\n",
      "\n",
      "Topic: game\n",
      "Precision: 0.9444\n",
      "Recall: 0.8095\n",
      "F1-Score: 0.8718\n",
      "Support: 21\n",
      "\n",
      "Topic: book\n",
      "Precision: 0.5000\n",
      "Recall: 0.2941\n",
      "F1-Score: 0.3704\n",
      "Support: 17\n",
      "\n",
      "Topic: tech\n",
      "Precision: 0.8125\n",
      "Recall: 0.8125\n",
      "F1-Score: 0.8125\n",
      "Support: 16\n",
      "\n",
      "Topic: relationships\n",
      "Precision: 0.6316\n",
      "Recall: 0.7059\n",
      "F1-Score: 0.6667\n",
      "Support: 17\n",
      "\n",
      "Accuracy: 0.6544\n",
      "Topic: macro avg\n",
      "Precision: 0.6944\n",
      "Recall: 0.6568\n",
      "F1-Score: 0.6674\n",
      "Support: 327\n",
      "\n",
      "Topic: weighted avg\n",
      "Precision: 0.6858\n",
      "Recall: 0.6544\n",
      "F1-Score: 0.6619\n",
      "Support: 327\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Model Evaluation\n",
    "accuracy = evaluator.evaluate(predictions)\n",
    "print(\"Accuracy: {:.4f}\".format(accuracy))\n",
    "\n",
    "# Classification Report\n",
    "from sklearn.metrics import classification_report\n",
    "y_true = predictions.select(\"label\").rdd.flatMap(lambda x: x).collect()\n",
    "y_pred = predictions.select(\"prediction\").rdd.flatMap(lambda x: x).collect()\n",
    "report = classification_report(y_true, y_pred, target_names=TARGET_CLASSES, output_dict=True)\n",
    "\n",
    "print(\"Classification Report for Testing Data:\")\n",
    "for topic, metrics in report.items():\n",
    "    if topic == 'accuracy':\n",
    "        print(f\"Accuracy: {metrics:.4f}\")\n",
    "    else:\n",
    "        print(f\"Topic: {topic}\")\n",
    "        print(f\"Precision: {metrics['precision']:.4f}\")\n",
    "        print(f\"Recall: {metrics['recall']:.4f}\")\n",
    "        print(f\"F1-Score: {metrics['f1-score']:.4f}\")\n",
    "        print(f\"Support: {metrics['support']:.0f}\")\n",
    "        print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------------------------------------------------------------------------------------+------------------------------------------------------------------------------------------------------------------------------------------------------------------+\n",
      "|title                                                                                  |original_title                                                                                                                                                    |\n",
      "+---------------------------------------------------------------------------------------+------------------------------------------------------------------------------------------------------------------------------------------------------------------+\n",
      "|week inclusive affect weight                                                           |How did a week all inclusive affect your weight?                                                                                                                  |\n",
      "|great pyramid egypt                                                                    |What if great pyramids not in Egypt?                                                                                                                              |\n",
      "|serious 30 acres land access water afford live want make land would                    |[serious]If you had 30 acres of land-locked land with no access to water and couldn’t afford to live on it but wanted to make $ off of the land what would you do?|\n",
      "|people rough relationship parent change move                                           |People who had a rough relationship with their parents, what changed when you moved out?                                                                          |\n",
      "|hat tv character                                                                       |Who’s the most hated TV character?                                                                                                                                |\n",
      "|think eastern countries allow men engage sexual relations animals feel need think gross|Why do you think eastern countries allow men to engage in sexual relations with animals if they feel the need, don't you think it is gross?                       |\n",
      "|best dad joke                                                                          |What's your best dad joke?                                                                                                                                        |\n",
      "|first time travel via plane guide upon arrival airport                                 |First time to travel via plane any guide on what to do upon arrival to the airport?                                                                               |\n",
      "|24 hour road trip one person past present would pick                                   |If you had to do a 24 hour road trip with one person past or present. Who would you pick and why?                                                                 |\n",
      "|green flag date                                                                        |What are some green flags of dating you?                                                                                                                          |\n",
      "|action take someone think know change opinion view                                     |What action taken by someone you thought you knew changed your opinion or view of them?                                                                           |\n",
      "|let say one day proof come prooves god afterlife would world react                     |lets say one day some proof comes that prooves there is no god or afterlife, how would the world react to that?                                                   |\n",
      "|coolest speak language                                                                 |what is the coolest spoken language and why?                                                                                                                      |\n",
      "|ask friends pay money borrow                                                           |How Do You Ask Your Friends To Pay You The Money They Borrowed??                                                                                                  |\n",
      "|something super weird everyone accept                                                  |What’s something super weird that everyone just accepts?                                                                                                          |\n",
      "|adult redditors kid like tell people think stupid                                      |Adult redditors what kid shows/movies/YouTubers do you like but if you tell people they think your stupid?                                                        |\n",
      "|reason bully deal impact                                                               |What were the reasons for you being bullied, how did you deal with it and how did it impact you?                                                                  |\n",
      "|samus women catwomen play black actress form media release today would get wake label  |\"Samus being a women, Catwomen played by a black actress, what other form of media if release today would get the \"\"Woke\"\" label?\"                                |\n",
      "|first impression prove totally wrong                                                   |What's a first impression you had that was proven totally wrong?                                                                                                  |\n",
      "|something happen real life never show                                                  |What is something that happens in real life but is never shown in movies/shows?                                                                                   |\n",
      "+---------------------------------------------------------------------------------------+------------------------------------------------------------------------------------------------------------------------------------------------------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "unseen_df = spark.read.csv(\"unseen-data.csv\", header=True, inferSchema=True)\n",
    "unseen_df_title = unseen_df.select(\"title\")\n",
    "unseen_df_title_original = unseen_df_title.withColumn(\"original_title\", unseen_df_title[\"title\"])\n",
    "\n",
    "preprocess_udf = udf(preprocess_text, StringType())\n",
    "unseen_df_title_original_processed = unseen_df_title_original.withColumn(\"title\", preprocess_udf(unseen_df_title_original[\"title\"]))\n",
    "\n",
    "unseen_df_title_original_processed.show(truncate=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions_unseen = cvModel.transform(unseen_df_title_original_processed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a UDF to calculate the maximum probability\n",
    "def max_probability(prob_list):\n",
    "    return float(max(prob_list))\n",
    "\n",
    "# Register the UDF\n",
    "max_prob_udf = udf(max_probability, DoubleType())\n",
    "\n",
    "# Add the max_prob column using the UDF\n",
    "predictions_unseen = predictions_unseen.withColumn(\"max_prob\", max_prob_udf(col(\"probability\")))\n",
    "\n",
    "label_to_class = {\n",
    "    0: \"money\",\n",
    "    1: \"sexual\",\n",
    "    2: \"health\",\n",
    "    3: \"kid\",\n",
    "    4: \"job\",\n",
    "    5: \"movies\",\n",
    "    6: \"relationships\",\n",
    "    7: \"food\",\n",
    "    8: \"videogame\",\n",
    "    9: \"media\",\n",
    "    10: \"music\",\n",
    "    11: \"tech\",\n",
    "    12: \"book\",\n",
    "    13: \"life\"\n",
    "}\n",
    "\n",
    "def map_label_to_class(label):\n",
    "    if label != \"other\":\n",
    "        return label_to_class.get(float(label))\n",
    "    else:\n",
    "        return \"other\"\n",
    "\n",
    "# Register the UDF\n",
    "map_label_udf = udf(map_label_to_class, StringType())\n",
    "\n",
    "predictions_unseen = predictions_unseen.withColumn(\n",
    "    \"predicted_category\",\n",
    "    when(predictions_unseen[\"max_prob\"] >= 0.3, predictions_unseen[\"prediction\"]).otherwise(\"other\")\n",
    ")\n",
    "\n",
    "predictions_unseen = predictions_unseen.withColumn(\n",
    "    \"predicted_category\",\n",
    "    map_label_udf(predictions_unseen[\"predicted_category\"])\n",
    ")\n",
    "\n",
    "\n",
    "# Select the desired columns\n",
    "selected_columns = predictions_unseen.select(\"original_title\", \"max_prob\", \"predicted_category\")\n",
    "\n",
    "# Collect the DataFrame into the driver program\n",
    "collected_data = selected_columns.collect()\n",
    "\n",
    "\n",
    "with open(\"predictions-unseen.csv\", \"w\", newline=\"\", encoding='UTF-8') as csv_file:\n",
    "    csv_writer = csv.writer(csv_file)\n",
    "    # Write header\n",
    "    csv_writer.writerow([\"original_title\", \"max_prob\", \"predicted_category\"])\n",
    "    # Write data\n",
    "    for row in collected_data:\n",
    "        csv_writer.writerow([row.original_title, row.max_prob, row.predicted_category])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
