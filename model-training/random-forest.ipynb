{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\HP\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\HP\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     C:\\Users\\HP\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------+-----+\n",
      "|topic_name   |count|\n",
      "+-------------+-----+\n",
      "|relationships|125  |\n",
      "|money        |152  |\n",
      "|food         |137  |\n",
      "|job          |134  |\n",
      "|life         |83   |\n",
      "|music        |76   |\n",
      "|media        |76   |\n",
      "|movie        |90   |\n",
      "|sexual       |149  |\n",
      "|health       |140  |\n",
      "|kid          |140  |\n",
      "|would        |110  |\n",
      "|game         |72   |\n",
      "|book         |73   |\n",
      "|tech         |112  |\n",
      "+-------------+-----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "from pyspark.ml import Pipeline\n",
    "from pyspark.ml.feature import Tokenizer, StopWordsRemover, CountVectorizer, IDF\n",
    "from pyspark.ml.classification import LinearSVC\n",
    "from pyspark.ml.evaluation import MulticlassClassificationEvaluator\n",
    "from pyspark.ml.tuning import ParamGridBuilder, CrossValidator\n",
    "from pyspark.sql.functions import udf, col\n",
    "from pyspark.sql.types import StringType\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "import nltk\n",
    "import re\n",
    "\n",
    "nltk.download('punkt')\n",
    "nltk.download('stopwords')\n",
    "nltk.download('wordnet')\n",
    "\n",
    "# Initialize SparkSession\n",
    "spark = SparkSession.builder.appName(\"TextClassification\").getOrCreate()\n",
    "\n",
    "\n",
    "# Load your dataset into a DataFrame\n",
    "df = spark.read.csv(\"testing-dataset.csv\", header=True, inferSchema=True)\n",
    "\n",
    "# Data Preprocessing\n",
    "lemmatizer = WordNetLemmatizer()\n",
    "stop_words = set(nltk.corpus.stopwords.words('english'))\n",
    "\n",
    "# UDF for preprocessing\n",
    "def preprocess_text(text):\n",
    "    text = re.sub(r'\"\"', '\"', text)\n",
    "    tokens = nltk.word_tokenize(text.lower())\n",
    "    tokens = [word for word in tokens if word.isalnum()]\n",
    "    tokens = [lemmatizer.lemmatize(word) for word in tokens if word not in stop_words]\n",
    "    return ' '.join(tokens)\n",
    "\n",
    "preprocess_udf = udf(preprocess_text, StringType())\n",
    "df = df.withColumn(\"title\", preprocess_udf(df[\"title\"]))\n",
    "target_classes = [row.topic_name for row in df.select(\"topic_name\").distinct().collect()]\n",
    "\n",
    "df.groupBy('topic_name').count().show(truncate=False)\n",
    "\n",
    "\n",
    "from pyspark.ml.feature import StringIndexer\n",
    "\n",
    "# Convert the topic_name column to numeric\n",
    "indexer = StringIndexer(inputCol=\"topic_name\", outputCol=\"label\")\n",
    "indexed_df = indexer.fit(df).transform(df)\n",
    "indexed_df = indexed_df.withColumn(\"label\", col(\"label\").cast(\"integer\"))\n",
    "\n",
    "\n",
    "# Split the dataset\n",
    "(train_df, test_df) = indexed_df.randomSplit([0.8, 0.2], seed=42)\n",
    "\n",
    "# TF-IDF Vectorization\n",
    "tokenizer = Tokenizer(inputCol=\"title\", outputCol=\"words\")\n",
    "remover = StopWordsRemover(inputCol=\"words\", outputCol=\"filtered_words\")\n",
    "cv = CountVectorizer(inputCol=\"filtered_words\", outputCol=\"raw_features\", vocabSize=1500)\n",
    "idf = IDF(inputCol=\"raw_features\", outputCol=\"features\")\n",
    "\n",
    "# Linear SVM model\n",
    "from pyspark.ml.classification import RandomForestClassifier\n",
    "\n",
    "# Random Forest model\n",
    "rf = RandomForestClassifier(labelCol=\"label\", featuresCol=\"features\", numTrees=100)\n",
    "\n",
    "# Modify the pipeline to use Random Forest\n",
    "pipeline = Pipeline(stages=[tokenizer, remover, cv, idf, rf])\n",
    "\n",
    "# Hyperparameter Tuning (Randomized Search)\n",
    "paramGrid = ParamGridBuilder() \\\n",
    "    .addGrid(rf.maxDepth, [5, 10, 15]) \\\n",
    "    .build()\n",
    "\n",
    "evaluator = MulticlassClassificationEvaluator(labelCol=\"label\", metricName=\"accuracy\")\n",
    "\n",
    "crossval = CrossValidator(estimator=pipeline,\n",
    "                          estimatorParamMaps=paramGrid,\n",
    "                          evaluator=evaluator,\n",
    "                          numFolds=5,\n",
    "                          seed=42)\n",
    "\n",
    "# Fit the model\n",
    "cvModel = crossval.fit(train_df)\n",
    "\n",
    "# Make predictions\n",
    "predictions = cvModel.transform(test_df)\n",
    "\n",
    "# Evaluation\n",
    "accuracy = evaluator.evaluate(predictions)\n",
    "print(\"Accuracy: {:.4f}\".format(accuracy))\n",
    "\n",
    "# Classification Report\n",
    "from sklearn.metrics import classification_report\n",
    "y_true = predictions.select(\"label\").rdd.flatMap(lambda x: x).collect()\n",
    "y_pred = predictions.select(\"prediction\").rdd.flatMap(lambda x: x).collect()\n",
    "report = classification_report(y_true, y_pred, target_names=target_classes, output_dict=True)\n",
    "\n",
    "print(\"Classification Report for Testing Data:\")\n",
    "for topic, metrics in report.items():\n",
    "    if topic == 'accuracy':\n",
    "        print(f\"Accuracy: {metrics:.4f}\")\n",
    "    else:\n",
    "        print(f\"Topic: {topic}\")\n",
    "        print(f\"Precision: {metrics['precision']:.4f}\")\n",
    "        print(f\"Recall: {metrics['recall']:.4f}\")\n",
    "        print(f\"F1-Score: {metrics['f1-score']:.4f}\")\n",
    "        print(f\"Support: {metrics['support']:.0f}\")\n",
    "        print()\n",
    "\n",
    "# Stop Spark\n",
    "spark.stop()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.5087\n",
      "Classification Report for Testing Data:\n",
      "Topic: relationships\n",
      "Precision: 0.7647\n",
      "Recall: 0.3514\n",
      "F1-Score: 0.4815\n",
      "Support: 37\n",
      "\n",
      "Topic: money\n",
      "Precision: 0.7143\n",
      "Recall: 0.5556\n",
      "F1-Score: 0.6250\n",
      "Support: 27\n",
      "\n",
      "Topic: food\n",
      "Precision: 0.1053\n",
      "Recall: 0.7143\n",
      "F1-Score: 0.1835\n",
      "Support: 14\n",
      "\n",
      "Topic: job\n",
      "Precision: 0.7600\n",
      "Recall: 0.7600\n",
      "F1-Score: 0.7600\n",
      "Support: 25\n",
      "\n",
      "Topic: life\n",
      "Precision: 0.6667\n",
      "Recall: 0.8235\n",
      "F1-Score: 0.7368\n",
      "Support: 17\n",
      "\n",
      "Topic: music\n",
      "Precision: 0.7778\n",
      "Recall: 0.5600\n",
      "F1-Score: 0.6512\n",
      "Support: 25\n",
      "\n",
      "Topic: media\n",
      "Precision: 0.4286\n",
      "Recall: 0.2857\n",
      "F1-Score: 0.3429\n",
      "Support: 21\n",
      "\n",
      "Topic: movie\n",
      "Precision: 0.7143\n",
      "Recall: 0.2083\n",
      "F1-Score: 0.3226\n",
      "Support: 24\n",
      "\n",
      "Topic: sexual\n",
      "Precision: 0.6000\n",
      "Recall: 0.1579\n",
      "F1-Score: 0.2500\n",
      "Support: 19\n",
      "\n",
      "Topic: health\n",
      "Precision: 0.8333\n",
      "Recall: 0.3846\n",
      "F1-Score: 0.5263\n",
      "Support: 13\n",
      "\n",
      "Topic: kid\n",
      "Precision: 0.5600\n",
      "Recall: 0.8750\n",
      "F1-Score: 0.6829\n",
      "Support: 16\n",
      "\n",
      "Topic: would\n",
      "Precision: 0.8750\n",
      "Recall: 0.3333\n",
      "F1-Score: 0.4828\n",
      "Support: 21\n",
      "\n",
      "Topic: game\n",
      "Precision: 1.0000\n",
      "Recall: 0.7500\n",
      "F1-Score: 0.8571\n",
      "Support: 8\n",
      "\n",
      "Topic: book\n",
      "Precision: 1.0000\n",
      "Recall: 0.6429\n",
      "F1-Score: 0.7826\n",
      "Support: 14\n",
      "\n",
      "Topic: tech\n",
      "Precision: 0.5833\n",
      "Recall: 0.8750\n",
      "F1-Score: 0.7000\n",
      "Support: 8\n",
      "\n",
      "Accuracy: 0.5087\n",
      "Topic: macro avg\n",
      "Precision: 0.6922\n",
      "Recall: 0.5518\n",
      "F1-Score: 0.5590\n",
      "Support: 289\n",
      "\n",
      "Topic: weighted avg\n",
      "Precision: 0.6962\n",
      "Recall: 0.5087\n",
      "F1-Score: 0.5401\n",
      "Support: 289\n",
      "\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
