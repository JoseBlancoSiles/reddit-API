{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import libraries\n",
    "\n",
    "# sparkML\n",
    "from pyspark.ml.classification import LinearSVC, OneVsRest\n",
    "from pyspark.ml.feature import Tokenizer, StopWordsRemover, CountVectorizer, IDF, StringIndexer\n",
    "from pyspark.ml.evaluation import MulticlassClassificationEvaluator\n",
    "from pyspark.ml import Pipeline\n",
    "\n",
    "# sparkSQL\n",
    "from pyspark.sql.functions import udf, col\n",
    "from pyspark.sql.types import StringType\n",
    "from pyspark.sql import SparkSession\n",
    "\n",
    "# other\n",
    "from sklearn.metrics import classification_report\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "import nltk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\HP\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\HP\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     C:\\Users\\HP\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Download nltk functions --> Necessary to remove stopwords and more to get better accuracy in our NLP ML model\n",
    "nltk.download(\"punkt\")\n",
    "nltk.download(\"stopwords\")\n",
    "nltk.download(\"wordnet\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize SparkSession\n",
    "spark = SparkSession.builder.appName(\"TextClassification\").getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# functions\n",
    "def preprocess_text(text):\n",
    "    '''Remove stop words, tokenize and clean the data from the title column. Original: |Cis Men of Reddit, if you were a woman, what would you like about Men?  --> PROCESSED: men reddit woman would like men''' \n",
    "    tokens = nltk.word_tokenize(text.lower(), language=\"english\")\n",
    "    tokens = [word for word in tokens if word.isalnum() and len(word) > 1]\n",
    "    tokens = [lemmatizer.lemmatize(word, pos=\"v\") for word in tokens if word not in stop_words]\n",
    "    return ' '.join(tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the labeled dataset into spark\n",
    "df = spark.read.csv(\"labeled-training-dataset.csv\", header=True, inferSchema=True)\n",
    "\n",
    "# We need a copy of the column, as we are going to tokenize and vectorize the title for better classification\n",
    "df = df.withColumn(\"original_title\", df[\"title\"])\n",
    "\n",
    "# Data Preprocessing\n",
    "lemmatizer = WordNetLemmatizer()\n",
    "stop_words = set(nltk.corpus.stopwords.words(\"english\"))\n",
    "\n",
    "# Create a list of unique values of the topic_name column in the csv file. Eventually, you will find some rows that contain a really rare character combination, so you avoid it creating specific previous topics.\n",
    "TARGET_CLASSES = [\"money\", \"food\", \"job\", \"life\", \"music\", \"media\", \"movie\", \"sexual\", \"health\", \"kid\", \"game\", \"book\", \"tech\", \"relationships\"]\n",
    "\n",
    "# Filter out the elements that are not falling in any of the classes due to a SyntaxError in the Reddit Sentence --> \"Is calling someone a \"\"plaything\"\" a porn term? If so, what type of porn/ kink content?\",sexual [Look at that combination of double \"\"]\n",
    "df = df.filter(df[\"topic_name\"].isin(TARGET_CLASSES))\n",
    "\n",
    "# Call the preprocess_text function to tokenize and lematize the title of the reddit post\n",
    "preprocess_udf = udf(preprocess_text, StringType())\n",
    "df = df.withColumn(\"title\", preprocess_udf(df[\"title\"]))\n",
    "\n",
    "# Convert the topic_name column to numeric\n",
    "indexer = StringIndexer(inputCol=\"topic_name\", outputCol=\"label\")\n",
    "indexed_df = indexer.fit(df).transform(df)\n",
    "indexed_df = indexed_df.withColumn(\"label\", col(\"label\").cast(\"integer\"))\n",
    "\n",
    "# Split the dataset\n",
    "(train_df, test_df) = indexed_df.randomSplit([0.8, 0.2], seed=42)\n",
    "\n",
    "# TF-IDF Vectorization --> Classic steps prior to training a Multiclassification model in NLP\n",
    "tokenizer = Tokenizer(inputCol=\"title\", outputCol=\"words\")\n",
    "remover = StopWordsRemover(inputCol=\"words\", outputCol=\"filtered_words\")\n",
    "cv = CountVectorizer(inputCol=\"filtered_words\", outputCol=\"raw_features\", vocabSize=1500)\n",
    "idf = IDF(inputCol=\"raw_features\", outputCol=\"features\")\n",
    "\n",
    "# LinearSVC model\n",
    "svm = LinearSVC(maxIter=100, regParam=0.01)\n",
    "\n",
    "# One-vs-Rest model\n",
    "ovr = OneVsRest(classifier=svm)\n",
    "\n",
    "# Modify the pipeline to use One-vs-Rest\n",
    "pipeline = Pipeline(stages=[tokenizer, remover, cv, idf, ovr])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fit the model\n",
    "ovr_model = pipeline.fit(train_df)\n",
    "\n",
    "# Make predictions\n",
    "predictions = ovr_model.transform(test_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.6391\n",
      "Classification Report for Testing Data:\n",
      "Topic: money\n",
      "Precision: 0.4815\n",
      "Recall: 0.4815\n",
      "F1-Score: 0.4815\n",
      "Support: 27\n",
      "\n",
      "Topic: food\n",
      "Precision: 0.7188\n",
      "Recall: 0.7931\n",
      "F1-Score: 0.7541\n",
      "Support: 29\n",
      "\n",
      "Topic: job\n",
      "Precision: 0.4250\n",
      "Recall: 0.6538\n",
      "F1-Score: 0.5152\n",
      "Support: 26\n",
      "\n",
      "Topic: life\n",
      "Precision: 0.9375\n",
      "Recall: 0.6250\n",
      "F1-Score: 0.7500\n",
      "Support: 24\n",
      "\n",
      "Topic: music\n",
      "Precision: 0.7222\n",
      "Recall: 0.5000\n",
      "F1-Score: 0.5909\n",
      "Support: 26\n",
      "\n",
      "Topic: media\n",
      "Precision: 0.8824\n",
      "Recall: 0.6522\n",
      "F1-Score: 0.7500\n",
      "Support: 23\n",
      "\n",
      "Topic: movie\n",
      "Precision: 0.3684\n",
      "Recall: 0.4667\n",
      "F1-Score: 0.4118\n",
      "Support: 30\n",
      "\n",
      "Topic: sexual\n",
      "Precision: 0.5789\n",
      "Recall: 0.5000\n",
      "F1-Score: 0.5366\n",
      "Support: 22\n",
      "\n",
      "Topic: health\n",
      "Precision: 0.9545\n",
      "Recall: 0.8750\n",
      "F1-Score: 0.9130\n",
      "Support: 24\n",
      "\n",
      "Topic: kid\n",
      "Precision: 0.7407\n",
      "Recall: 0.8000\n",
      "F1-Score: 0.7692\n",
      "Support: 25\n",
      "\n",
      "Topic: game\n",
      "Precision: 0.9412\n",
      "Recall: 0.7619\n",
      "F1-Score: 0.8421\n",
      "Support: 21\n",
      "\n",
      "Topic: book\n",
      "Precision: 0.4545\n",
      "Recall: 0.2941\n",
      "F1-Score: 0.3571\n",
      "Support: 17\n",
      "\n",
      "Topic: tech\n",
      "Precision: 0.8235\n",
      "Recall: 0.8750\n",
      "F1-Score: 0.8485\n",
      "Support: 16\n",
      "\n",
      "Topic: relationships\n",
      "Precision: 0.4615\n",
      "Recall: 0.7059\n",
      "F1-Score: 0.5581\n",
      "Support: 17\n",
      "\n",
      "Accuracy: 0.6391\n",
      "Topic: macro avg\n",
      "Precision: 0.6779\n",
      "Recall: 0.6417\n",
      "F1-Score: 0.6484\n",
      "Support: 327\n",
      "\n",
      "Topic: weighted avg\n",
      "Precision: 0.6734\n",
      "Recall: 0.6391\n",
      "F1-Score: 0.6453\n",
      "Support: 327\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Evaluation\n",
    "evaluator = MulticlassClassificationEvaluator(labelCol=\"label\", metricName=\"accuracy\")\n",
    "accuracy = evaluator.evaluate(predictions)\n",
    "print(\"Accuracy: {:.4f}\".format(accuracy))\n",
    "\n",
    "# Classification Report\n",
    "y_true = predictions.select(\"label\").rdd.flatMap(lambda x: x).collect()\n",
    "y_pred = predictions.select(\"prediction\").rdd.flatMap(lambda x: x).collect()\n",
    "report = classification_report(y_true, y_pred, target_names=TARGET_CLASSES, output_dict=True)\n",
    "\n",
    "print(\"Classification Report for Testing Data:\")\n",
    "for topic, metrics in report.items():\n",
    "    if topic == 'accuracy':\n",
    "        print(f\"Accuracy: {metrics:.4f}\")\n",
    "    else:\n",
    "        print(f\"Topic: {topic}\")\n",
    "        print(f\"Precision: {metrics['precision']:.4f}\")\n",
    "        print(f\"Recall: {metrics['recall']:.4f}\")\n",
    "        print(f\"F1-Score: {metrics['f1-score']:.4f}\")\n",
    "        print(f\"Support: {metrics['support']:.0f}\")\n",
    "        print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "spark.stop()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
